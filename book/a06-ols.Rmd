---
output: html_document
editor_options: 
  chunk_output_type: console
---

# (PART) Regression {-}

# OLS regression {#olsreg}

To provide a simple example of how to conduct an OLS regression, we will use the same data as in the visualisation chapter, i.e. the `states` data frame from the package `poliscidata`.

```{r, message=FALSE, warning=FALSE}
library("poliscidata")

states <- states
```


## Bivariate linear regression

To conduct a bivariate linear regression, we use the `lm()` function (short for linear models). We need to specify the dependent variable, independent variable and the data frame. Below we specify `obama2012` as the dependent variable and `abort_rate08` as the independent variable. Notice that we use the `~` symbol to separate the dependent variable from the independent variable. We save the output in the object `reg_obama`.

```{r, message=FALSE, warning=FALSE}
reg_obama <- lm(obama2012 ~ abort_rate08, data = states)
```

If we type `reg_obama`, we can see the intercept and coefficient in the model.

```{r, message=FALSE, warning=FALSE}
reg_obama
```

Here we see that the intercept is 35.26, which is the predicted vote share for Obama in 2012 when we extrapolate to a state with an abortion rate of 0. The coefficient is 0.83, which is the increase in the vote share for Obama when there is an one-unit increase in the abortion rate.

However, this is not enough information. We need, for example, also information on the standard errors as well as model statistics. To get this, we use the function `summary()` on our object.


```{r, message=FALSE, warning=FALSE}
summary(reg_obama)
```

Here we can see that the estimate for `abort_rate08` is statistically significant. We can further see that the R-squared is 0.46 which indicates that 46% of the variation in the vote share is explained by our independent variable.

To convert the results from our analysis into a data frame, we can use the package `broom` [@Robinson2018].


```{r, message=FALSE, warning=FALSE}
library("broom")
```

As a first example, we can save the estimates and test statistics in a data frame by using the function `tidy()`. We save the output in a new object `reg_obama_tidy` and show this output as well.

```{r, message=FALSE, warning=FALSE}
reg_obama_tidy <- tidy(reg_obama)

reg_obama_tidy
```

If we would also like to have the confidence intervals, we can add the `conf.int = TRUE`. 

```{r, message=FALSE, warning=FALSE}
reg_obama_tidy <- tidy(reg_obama, conf.int = TRUE)

reg_obama_tidy
```

This is useful if you would like to visualise the results. However, often we also want to save predictions and residuals based on our model. To do this, we can use the function `augment()`. Below we save the output in the object `reg_obama_aug`.


```{r, message=FALSE, warning=FALSE}
reg_obama_aug <- augment(reg_obama)
```


To see the data in the new object, use `head()`. Here you see that there is a variable called `.fitted`. This variable is the predicted value for each observation.

```{r, message=FALSE, warning=FALSE}
head(reg_obama_aug)
```

We can use this data frame to visualise the residuals (with the colour red below).

```{r, message=FALSE, warning=FALSE}
ggplot(reg_obama_aug, aes(x=abort_rate08, y=obama2012)) +
  geom_segment(aes(xend=abort_rate08, y=obama2012, yend=.fitted), 
        colour="red") +
  geom_point() +
  geom_line(aes(x=abort_rate08, y=.fitted)) 
```

## Multiple linear regression

To conduct a multiple linear regression, we simply need to add an extra variable to our model. Accordingly, the only difference between the example above and the example here is the addition of a new variable. Here, we want to examine whether the effect of `abort_rate08` holds when we control for population density (`density`). Notice that we add a `+` before adding the variable to the list of variables.

```{r, message=FALSE, warning=FALSE}
reg_obama_full <- lm(obama2012 ~ abort_rate08 + density, data = states)
```

We use the `summary()` function to get the output of the model.

```{r, message=FALSE, warning=FALSE}
summary(reg_obama_full)
```

In the output we see that the coefficient for `abort_rate08` is slightly smaller compared to the bivariate model but still statistically significant. Again we can use the `tidy()` function to get a data frame with the results.

```{r, message=FALSE, warning=FALSE}
reg_obama_full_tidy <- tidy(reg_obama_full)
```

We further calculate the 95% confidence intervals for the estimates.

```{r, message=FALSE, warning=FALSE}
reg_obama_full_tidy <- reg_obama_full_tidy %>%
  mutate(
    ci_low = estimate - 1.96 * std.error,
    ci_high = estimate + 1.96 * std.error
  ) 
```

We can then visualise the results.

```{r, message=FALSE, warning=FALSE}
ggplot(reg_obama_full_tidy, aes(estimate, term, xmin = ci_low, 
                                xmax = ci_high, height = 0)) +
     geom_point() +
     geom_vline(xintercept = 0) +
     geom_errorbarh()
```

In some cases the intercept is not relevant. In the code below, we use the `filter()` function to visualise all effects except for the intercept.

```{r, message=FALSE, warning=FALSE}
reg_obama_full_tidy %>%
  filter(term != "(Intercept)") %>%
  ggplot(aes(estimate, term, xmin = ci_low, 
             xmax = ci_high, height = 0)) +
     geom_point() +
     geom_vline(xintercept = 0) +
     geom_errorbarh()
```

## Diagnostic tests 

To get diagnostic plots, we will use the `fortify()` function from `ggplot2`. This allows us to get the following variables realted to model fit statistics:

1. `.hat`: Diagonal of the hat matrix
2. `.sigma`: Estimate of residual standard deviation when corresponding observation is dropped from model
3. `.cooksd`: Cooks distance, using `cooks.distance()`
4. `.fitted`: Fitted values of model
5. `.resid`: Residuals
6. `.stdresid`: Standardised residuals

First, we use `fortify()` on our linear model:

```{r, message=FALSE, warning=FALSE} 
reg_fortify <- fortify(reg_obama_full)
```

To see how our residuals are in relation to our fitted values, we can plot `.fitted` and `.resid`.

```{r, message=FALSE, warning=FALSE} 
ggplot(reg_fortify, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  labs(title = "Residuals vs. Fitted",
       y = "Residuals",
       x = "Fitted values")
```

To see whether our residuals are normally distributed, we create a normal Q-Q plot with the standardized residuals.

```{r, message=FALSE, warning=FALSE} 
ggplot(reg_fortify) +
  stat_qq(aes(sample = .stdresid)) +
  geom_abline() +
  labs(title = "Normal Q-Q",
       y = "Standardized residuals",
       x = "Theoretical Quantiles")
```


To estimate the influence of individual observations, we plot the Cook's distance for each state.

```{r, message=FALSE, warning=FALSE} 
ggplot(reg_fortify, aes(x = seq_along(.cooksd), y = .cooksd)) +
  geom_col()  +
  labs(title = "Cook's distance",
       y = "Cook's distance",
       x = "Obs. number")
```


## Setting up regression tables

To export regression tables from `R`, we are going to use the package `stargazer` (remember to install the package if you haven't already done so).

```{r, message=FALSE, warning=FALSE} 
library("stargazer")
```

First, we use the `stargazer()` function to show the output from the object `reg_obama`. Notice that we also add the option `type = "text"`. If we do not do that, we will get the output as LaTeX code. 

```{r, message=FALSE, warning=FALSE} 
stargazer(reg_obama, type = "text")
```

This shows the output from one regression model. To add more regression models to the table, simply add a comma and the name of the object with the model. Below we use the same code as above and add the model with control variables included, `reg_obama_full`.

```{r, message=FALSE, warning=FALSE} 
stargazer(reg_obama, reg_obama_full, type = "text")
```

### Exporting the regression table

To export the regression table, we use the option `out` to specify, where we want to save our regresion table. Below we save the table in the file `tab-regression.htm`.

```{r, eval=FALSE, message=FALSE, warning=FALSE}
stargazer(reg_obama, reg_obama_full, type = "text",
          out="tab-regression.htm")
```

An `.htm` file is a HTML file you can open in your browser (e.g. Google Chrome). To get it into Word, simply open the file via Word. You might have to do some extra changes before it is ready for a broader audience. Always try to make your tables look like tables in published articles and books.